{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "swiggy data extraction.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPMnPwfwy+YSOJTXRlo5zG0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaithaniAR/Web-scraping-for-reddit/blob/main/swiggy_data_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_fkYtEv34ja",
        "outputId": "06506eb3-7cf9-4101-a146-80a645c08a27"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting BeautifulSoup\n",
            "  Downloading BeautifulSoup-3.2.2.tar.gz (32 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/40/f2/6c9f2f3e696ee6a1fb0e4d7850617e224ed2b0b1e872110abffeca2a09d4/BeautifulSoup-3.2.2.tar.gz#sha256=a04169602bff6e3138b1259dbbf491f5a27f9499dea9a8fbafd48843f9d89970 (from https://pypi.org/simple/beautifulsoup/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading BeautifulSoup-3.2.1.tar.gz (31 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/1e/ee/295988deca1a5a7accd783d0dfe14524867e31abb05b6c0eeceee49c759d/BeautifulSoup-3.2.1.tar.gz#sha256=6a8cb4401111e011b579c8c52a51cdab970041cc543814bbd9577a4529fe1cdb (from https://pypi.org/simple/beautifulsoup/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "  Downloading BeautifulSoup-3.2.0.tar.gz (31 kB)\n",
            "\u001b[33mWARNING: Discarding https://files.pythonhosted.org/packages/33/fe/15326560884f20d792d3ffc7fe8f639aab88647c9d46509a240d9bfbb6b1/BeautifulSoup-3.2.0.tar.gz#sha256=0dc52d07516c1665c9dd9f0a390a7a054bfb7b147a50b2866fb116b8909dfd37 (from https://pypi.org/simple/beautifulsoup/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\u001b[0m\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement BeautifulSoup (from versions: 3.2.0, 3.2.1, 3.2.2)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for BeautifulSoup\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "AnN-6yTd3ldQ",
        "outputId": "90707771-c213-4ddb-dbfc-fefe49f3d511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Recommended': ['1 Chocolate Delight + 1 Classic Thick Shakes', '1 Chocolate Delight + 1 Fruity Delight Thick Shakes', '1 Fruity Delight + 1 Classic Thick Shakes', 'Choco Brownie Crumble Thick Shake', 'Peanut Butter Indulgence Thick Shake', 'Mexican Vanilla Thick Shake'], 'Real Fruit Thickshakes [New Launch]': ['Real Mango Fruit Thickshake', 'Real Strawberry Fruit Thickshake', 'Real Banana Fruit Thickshake'], 'Thick Friends Value Combos': ['1 Chocolate Delight + 1 Classic Thick Shakes', '1 Chocolate Delight + 1 Fruity Delight Thick Shakes', '1 Fruity Delight + 1 Classic Thick Shakes'], 'Thick shakes': ['Chocolate Delights', 'Belgian Chocolate Thick Shake', 'Choco Brownie Crumble Thick Shake', 'Nutella Brownie Crumble Thick Shake', 'Nutella Chocolate Blast Thick Shake', 'Peanut Butter Indulgence Thick Shake', 'Classic Shakes', 'Blueberry Delight Thick Shake', 'Caramel Carnival Thick Shake', 'Crunchy Butterscotch Thick Shake', 'Mexican Vanilla Thick Shake', 'Triple Choco Chip Thick Shake', 'Very Berry Thick Shake', 'Koffee Indulgences', 'Choco Koffee Thick Shake', 'Nutella Latte Thick Shake', 'Exotic Addictions', 'Caramel Butterscotch Thick Shake', 'Nutty Delights', 'Fig Almonds Joy Thick Shake'], 'Shape Your Shake': ['Shape Your Shake'], 'Milk shakes': ['Chocolate Delights', 'Belgian Chocolate Milk Shake', 'Classic Shakes', 'Crunchy Butterscotch Milk Shake', 'Mexican Vanilla Milk Shake', 'Triple Choco Chip Milk Shake', 'Fruity Delights', 'Real Mango Fruit Milkshake', 'Real Strawberry Fruit Milkshake', 'Real Banana Fruit Milkshake'], 'Slushes': ['Mojito Mint Slush', 'Blue Angel Slush', 'Blueberry Slush', 'Strawberry Slush', 'Tangy Orange Slush', 'Tropical Freshner Slush']}\n",
            "20\n",
            "['Chocolate Delights', 'Belgian Chocolate Thick Shake', 'Choco Brownie Crumble Thick Shake', 'Nutella Brownie Crumble Thick Shake', 'Nutella Chocolate Blast Thick Shake', 'Peanut Butter Indulgence Thick Shake', 'Classic Shakes', 'Blueberry Delight Thick Shake', 'Caramel Carnival Thick Shake', 'Crunchy Butterscotch Thick Shake', 'Mexican Vanilla Thick Shake', 'Triple Choco Chip Thick Shake', 'Very Berry Thick Shake', 'Koffee Indulgences', 'Choco Koffee Thick Shake', 'Nutella Latte Thick Shake', 'Exotic Addictions', 'Caramel Butterscotch Thick Shake', 'Nutty Delights', 'Fig Almonds Joy Thick Shake']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"for l in categories:\\n    loc.append(l.h4)\\nprint(loc[4][:len(loc[4])-1])\\nRatings = soup.find_all('div', class_ = 'sc-1q7bklc-5 clCBXa')\\nrate=[]\\nfor r in Ratings:\\n    rate.append(r.text)\\nprint(f'Ratings = {rate[-1][:3]}⭐')\\nsections = soup.find_all('p')\\ns=[]\\nfor sec in sections:\\n    s.append(sec.text)\\nprint(s[3:])\\n#sections = soup.find_all('p')\\n#s=[]\\n#k=[]\\n#for sec in sections:\\n#    k.append(sec.text)\\n#k=k[:15]\\n#for i in range(len(k)):\\n#    if k[i][-1]==')':\\n#        s.append(k[i])\\n#location = soup.find_all('span', class_ = 'sc-ks3f96-1 gETRUR')\\n#loc=[]\\n#for l in location:\\n#    loc.append(l.text)\\n#print(loc[4][:len(loc[4])-1])\\n#Ratings = soup.find_all('div', class_ = 'sc-1q7bklc-5 clCBXa')\\n#rate=[]\\n#for r in Ratings:\\n#    rate.append(r.text)\\n#print(f'Ratings = {rate[-1][:3]}⭐')\\n#sections = soup.find_all('p')\\n#s=[]\\n#for sec in sections:\\n#    s.append(sec.text)\\n#print(s[3:])\\n#sections = soup.find_all('p')\\n#s=[]\\n#k=[]\\n#for sec in sections:\\n#    k.append(sec.text)\\n#k=k[:15]\\n#for i in range(len(k)):\\n#    if k[i][-1]==')':\\n#        s.append(k[i])\\n#print(s)\\n#locate = soup.find('h4', class_ = 'sc-1s0saks-15 iSmBPS').text\\n#products = soup.find_all('h4', class_ = 'sc-1s0saks-15 iSmBPS')\\n#print(products)\\n#l=[]\\n#for product in products:\\n#    l.append(product.text)\\n#print(l)\\n #   product_name = product.find('div', class_ = 'styles_itemName__hLfgz').text\\n  #  price = product.find('span', class_ = 'rupee').text\\n   # print(f'Product = {product_name}')\\n    #print(f'Price = ₹{price}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "link='https://www.swiggy.com/restaurants/the-thick-shake-factory-indira-nagar-indiranagar-bangalore-405906' #input('Enter the URL:')\n",
        "hdr = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko/20100101 Firefox/84.0',\n",
        "       'Accept-Language' : 'en-GB,enl;q=0.5',\n",
        "       'Referer' : 'https://google.com',\n",
        "       'DNT' : '1'}\n",
        "header = {'User-Agent':'Mozilla/5.0 (Macintosh: Intel Mac OS X 10 11 2) AppleWebKit/601.3.9 (KHTML, like Gecko) Version/9.0.2 Safari/601.3.9'}\n",
        "\n",
        "\n",
        "html = requests.get(link, headers = hdr)\n",
        "soup = BeautifulSoup(html.content, 'lxml')\n",
        "section = soup.find_all('div', class_='_2dS-v')  # all the h2 tags are the categories\n",
        "s = []\n",
        "t = []\n",
        "for sec in section:\n",
        "    title = sec.find('h2').text\n",
        "    products=sec.find_all('h3')\n",
        "    r = []\n",
        "    for prod in products:\n",
        "        r.append(prod.text)\n",
        "    s.append(title)\n",
        "    t.append(r)\n",
        "\n",
        "y=dict(zip(s,t))\n",
        "print(y)\n",
        "print(len(y['Thick shakes']))\n",
        "print(y['Thick shakes'])\n",
        "\n",
        "\n",
        "'''for l in categories:\n",
        "    loc.append(l.h4)\n",
        "print(loc[4][:len(loc[4])-1])\n",
        "Ratings = soup.find_all('div', class_ = 'sc-1q7bklc-5 clCBXa')\n",
        "rate=[]\n",
        "for r in Ratings:\n",
        "    rate.append(r.text)\n",
        "print(f'Ratings = {rate[-1][:3]}⭐')\n",
        "sections = soup.find_all('p')\n",
        "s=[]\n",
        "for sec in sections:\n",
        "    s.append(sec.text)\n",
        "print(s[3:])\n",
        "#sections = soup.find_all('p')\n",
        "#s=[]\n",
        "#k=[]\n",
        "#for sec in sections:\n",
        "#    k.append(sec.text)\n",
        "#k=k[:15]\n",
        "#for i in range(len(k)):\n",
        "#    if k[i][-1]==')':\n",
        "#        s.append(k[i])\n",
        "#location = soup.find_all('span', class_ = 'sc-ks3f96-1 gETRUR')\n",
        "#loc=[]\n",
        "#for l in location:\n",
        "#    loc.append(l.text)\n",
        "#print(loc[4][:len(loc[4])-1])\n",
        "#Ratings = soup.find_all('div', class_ = 'sc-1q7bklc-5 clCBXa')\n",
        "#rate=[]\n",
        "#for r in Ratings:\n",
        "#    rate.append(r.text)\n",
        "#print(f'Ratings = {rate[-1][:3]}⭐')\n",
        "#sections = soup.find_all('p')\n",
        "#s=[]\n",
        "#for sec in sections:\n",
        "#    s.append(sec.text)\n",
        "#print(s[3:])\n",
        "#sections = soup.find_all('p')\n",
        "#s=[]\n",
        "#k=[]\n",
        "#for sec in sections:\n",
        "#    k.append(sec.text)\n",
        "#k=k[:15]\n",
        "#for i in range(len(k)):\n",
        "#    if k[i][-1]==')':\n",
        "#        s.append(k[i])\n",
        "#print(s)\n",
        "#locate = soup.find('h4', class_ = 'sc-1s0saks-15 iSmBPS').text\n",
        "#products = soup.find_all('h4', class_ = 'sc-1s0saks-15 iSmBPS')\n",
        "#print(products)\n",
        "#l=[]\n",
        "#for product in products:\n",
        "#    l.append(product.text)\n",
        "#print(l)\n",
        " #   product_name = product.find('div', class_ = 'styles_itemName__hLfgz').text\n",
        "  #  price = product.find('span', class_ = 'rupee').text\n",
        "   # print(f'Product = {product_name}')\n",
        "    #print(f'Price = ₹{price}')\n",
        "'''"
      ]
    }
  ]
}